{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a28b6298",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using downloaded and verified file: /home/lotfimecharbat/.medmnist/dermamnist.npz\n",
      "Using downloaded and verified file: /home/lotfimecharbat/.medmnist/dermamnist.npz\n",
      "Using downloaded and verified file: /home/lotfimecharbat/.medmnist/dermamnist.npz\n"
     ]
    }
   ],
   "source": [
    "from dataload import get_dataloaders\n",
    "\n",
    "train,test,val,info = get_dataloaders('DermaMNIST',batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ff75dd6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7913965",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/lotfimecharbat/.cache/torch/hub/mit-han-lab_once-for-all_master\n",
      "Downloading: \"https://huggingface.co/han-cai/ofa/resolve/main/ofa_supernet_resnet50\" to .torch/ofa_nets/ofa_supernet_resnet50\n",
      "/home/lotfimecharbat/Projects/MedNNS/ofa/model_zoo.py:106: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  init = torch.load(pt_path, map_location=\"cpu\")[\"state_dict\"]\n"
     ]
    }
   ],
   "source": [
    "from ofa.imagenet_classification.networks import ResNets\n",
    "from ofa.imagenet_classification.elastic_nn.modules.dynamic_layers import DynamicMBConvLayer, DynamicConvLayer, DynamicLinearLayer\n",
    "import torch\n",
    "\n",
    "super_net = torch.hub.load('mit-han-lab/once-for-all', 'ofa_supernet_resnet50', pretrained=True)\n",
    "n_classes = 40\n",
    "\n",
    "# Modify classifier for the dataset\n",
    "super_net.classifier = DynamicLinearLayer([super_net.classifier.linear.linear.in_features], n_classes)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "89f416bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 40])\n"
     ]
    }
   ],
   "source": [
    "# test supernet\n",
    "x = torch.randn(1, 3, 244, 244)\n",
    "logits = super_net(x)\n",
    "print(logits.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6034716f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'d': [2, 1, 0, 2, 1], 'e': [0.35, 0.35, 0.35, 0.35, 0.35, 0.35, 0.35, 0.35, 0.35, 0.35, 0.35, 0.35, 0.35, 0.35, 0.35, 0.35, 0.35, 0.35], 'w': [1, 0, 2, 2, 1, 1]}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "24502520"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "# test subnetwork\n",
    "def sample_active_subnet(supernet, sample_config):\n",
    "    \"\"\"\n",
    "    Sample and set an active subnet configuration.\n",
    "    \"\"\"\n",
    "    # sample expand ratio\n",
    "    if isinstance(sample_config['e'][0], list):\n",
    "        expand_setting = [random.choice(sample_config['e'][i]) for i in range(len(sample_config['e']))]\n",
    "    else:\n",
    "        expand_setting = [random.choice(sample_config['e']) for _ in range(len(supernet.blocks))]\n",
    "\n",
    "    # sample depth\n",
    "    depth_setting = []\n",
    "    for stage_id in range(len(sample_config['d'])):\n",
    "        depth_list = sample_config['d'][stage_id]\n",
    "        depth_setting.append(random.choice(depth_list))\n",
    "\n",
    "    # sample width_mult\n",
    "    width_mult_index = [random.choice(sample_config['w'][i]) for i in range(len(sample_config['w']))]\n",
    "    width_mult_setting = [\n",
    "        list(range(len(supernet.input_stem[0].out_channel_list)))[width_mult_index[0]],\n",
    "        list(range(len(supernet.input_stem[2].out_channel_list)))[width_mult_index[1]],\n",
    "    ]\n",
    "    for stage_id, block_idx in enumerate(supernet.grouped_block_index):\n",
    "        stage_first_block = supernet.blocks[block_idx[0]]\n",
    "        width_mult_setting.append(\n",
    "            list(range(len(stage_first_block.out_channel_list)))[width_mult_index[stage_id+2]]\n",
    "        )\n",
    "\n",
    "    arch_config = {\"d\": depth_setting, \"e\": expand_setting, \"w\": width_mult_setting}\n",
    "    supernet.set_active_subnet(**arch_config)\n",
    "    return arch_config\n",
    "\n",
    "sample_config={\"d\": [[0, 1, 2], [0, 1, 2], [0, 1, 2], [0, 1, 2], [0, 1, 2]],\n",
    "        \"e\": [0.35],\n",
    "        \"w\": [[0, 1, 2], [0, 1, 2], [0, 1, 2], [0, 1, 2], [0, 1, 2], [0, 1, 2]]}\n",
    "\n",
    "arch_config = sample_active_subnet(super_net, sample_config)\n",
    "subnet=super_net.get_active_subnet()\n",
    "# calculate n params\n",
    "print(arch_config)\n",
    "sum(p.numel() for p in subnet.parameters())- sum(p.numel() for p in super_net.classifier.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f063924b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'PathMNIST': './work_dir/Supernets/PathMNIST/super_net_complete_with_sandwich.pth', 'ChestMNIST': './work_dir/Supernets/ChestMNIST/super_net_complete_with_sandwich.pth', 'DermaMNIST': './work_dir/Supernets/DermaMNIST/super_net_complete_with_sandwich.pth', 'OCTMNIST': './work_dir/Supernets/OCTMNIST/super_net_complete_with_sandwich.pth', 'PneumoniaMNIST': './work_dir/Supernets/PneumoniaMNIST/super_net_complete_with_sandwich.pth', 'RetinaMNIST': './work_dir/Supernets/RetinaMNIST/super_net_complete_with_sandwich.pth', 'BreastMNIST': './work_dir/Supernets/BreastMNIST/super_net_complete_with_sandwich.pth', 'BloodMNIST': './work_dir/Supernets/BloodMNIST/super_net_complete_with_sandwich.pth', 'TissueMNIST': './work_dir/Supernets/TissueMNIST/super_net_complete_with_sandwich.pth', 'OrganAMNIST': './work_dir/Supernets/OrganAMNIST/super_net_complete_with_sandwich.pth', 'OrganCMNIST': './work_dir/Supernets/OrganCMNIST/super_net_complete_with_sandwich.pth', 'OrganSMNIST': './work_dir/Supernets/OrganSMNIST/super_net_complete_with_sandwich.pth'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/lotfimecharbat/.cache/torch/hub/mit-han-lab_once-for-all_master\n",
      "/home/lotfimecharbat/Projects/MedNNS/ofa/model_zoo.py:106: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  init = torch.load(pt_path, map_location=\"cpu\")[\"state_dict\"]\n",
      "/tmp/ipykernel_1165437/7141334.py:245: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  supernet.load_state_dict(torch.load(model_path, map_location=device)['state_dict'])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using downloaded and verified file: /home/lotfimecharbat/.medmnist/dermamnist.npz\n",
      "Using downloaded and verified file: /home/lotfimecharbat/.medmnist/dermamnist.npz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating sampled subnets: 100%|██████████| 10/10 [00:58<00:00,  5.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation completed for DermaMNIST\n",
      "Number of results: 10\n",
      "[{'subnet_config': {'w': [0, 2, 0, 2, 2, 2], 'd': [0, 0, 0, 2, 2], 'e': [0.35, 0.2, 0.2, 0.35, 0.25, 0.2, 0.2, 0.2, 0.35, 0.2, 0.35, 0.35, 0.35, 0.2, 0.35, 0.25, 0.2, 0.2]}, 'num_parameters': 30036207, 'val_accuracy': 71.78464606181456, 'test_accuracy': 72.56857855361596}, {'subnet_config': {'w': [0, 2, 1, 2, 0, 1], 'd': [0, 1, 1, 2, 1], 'e': [0.35, 0.25, 0.2, 0.25, 0.35, 0.25, 0.2, 0.2, 0.35, 0.25, 0.25, 0.25, 0.2, 0.2, 0.25, 0.2, 0.2, 0.25]}, 'num_parameters': 12059463, 'val_accuracy': 71.5852442671984, 'test_accuracy': 71.52119700748129}, {'subnet_config': {'w': [1, 1, 0, 2, 1, 2], 'd': [1, 1, 2, 1, 0], 'e': [0.2, 0.35, 0.25, 0.35, 0.35, 0.25, 0.35, 0.2, 0.35, 0.2, 0.2, 0.35, 0.2, 0.25, 0.2, 0.2, 0.2, 0.25]}, 'num_parameters': 13334335, 'val_accuracy': 72.08374875373879, 'test_accuracy': 71.52119700748129}, {'subnet_config': {'w': [1, 1, 0, 0, 2, 2], 'd': [1, 0, 0, 0, 1], 'e': [0.35, 0.35, 0.2, 0.35, 0.35, 0.2, 0.35, 0.35, 0.2, 0.2, 0.25, 0.25, 0.25, 0.35, 0.35, 0.35, 0.2, 0.35]}, 'num_parameters': 24307823, 'val_accuracy': 74.77567298105683, 'test_accuracy': 75.01246882793018}, {'subnet_config': {'w': [2, 1, 0, 0, 0, 0], 'd': [2, 1, 1, 0, 0], 'e': [0.25, 0.2, 0.35, 0.25, 0.25, 0.35, 0.25, 0.2, 0.25, 0.2, 0.2, 0.35, 0.35, 0.35, 0.25, 0.35, 0.35, 0.25]}, 'num_parameters': 8536327, 'val_accuracy': 72.78165503489531, 'test_accuracy': 72.76807980049875}, {'subnet_config': {'w': [1, 1, 0, 1, 0, 2], 'd': [2, 1, 2, 1, 0], 'e': [0.35, 0.2, 0.35, 0.25, 0.35, 0.2, 0.25, 0.25, 0.35, 0.25, 0.35, 0.25, 0.35, 0.2, 0.35, 0.35, 0.2, 0.35]}, 'num_parameters': 20145535, 'val_accuracy': 73.08075772681954, 'test_accuracy': 74.06483790523691}, {'subnet_config': {'w': [1, 1, 0, 0, 0, 2], 'd': [2, 1, 1, 0, 0], 'e': [0.35, 0.25, 0.35, 0.2, 0.35, 0.2, 0.35, 0.25, 0.35, 0.35, 0.35, 0.2, 0.2, 0.25, 0.2, 0.35, 0.35, 0.2]}, 'num_parameters': 15174143, 'val_accuracy': 73.77866400797608, 'test_accuracy': 75.06234413965088}, {'subnet_config': {'w': [1, 2, 2, 1, 1, 2], 'd': [2, 2, 0, 2, 1], 'e': [0.2, 0.2, 0.35, 0.25, 0.2, 0.35, 0.2, 0.2, 0.35, 0.25, 0.35, 0.2, 0.25, 0.35, 0.35, 0.25, 0.2, 0.35]}, 'num_parameters': 22721503, 'val_accuracy': 68.49451645064805, 'test_accuracy': 68.87780548628429}, {'subnet_config': {'w': [0, 1, 2, 1, 0, 2], 'd': [0, 0, 1, 0, 2], 'e': [0.25, 0.2, 0.2, 0.2, 0.2, 0.25, 0.2, 0.35, 0.35, 0.2, 0.35, 0.2, 0.2, 0.2, 0.35, 0.35, 0.2, 0.2]}, 'num_parameters': 25127279, 'val_accuracy': 74.4765702891326, 'test_accuracy': 75.06234413965088}, {'subnet_config': {'w': [0, 1, 2, 1, 0, 0], 'd': [0, 2, 2, 2, 0], 'e': [0.2, 0.35, 0.35, 0.35, 0.25, 0.2, 0.25, 0.25, 0.2, 0.2, 0.2, 0.35, 0.25, 0.25, 0.25, 0.25, 0.25, 0.35]}, 'num_parameters': 8703503, 'val_accuracy': 67.79661016949153, 'test_accuracy': 68.82793017456359}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim import SGD\n",
    "from torch.nn import CrossEntropyLoss\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "import torch.nn.functional as F\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "from medmnist import INFO, Evaluator\n",
    "from medmnist import (DermaMNIST, PneumoniaMNIST, PathMNIST, RetinaMNIST, \n",
    "                      BreastMNIST, BloodMNIST, ChestMNIST, OCTMNIST, \n",
    "                      OrganCMNIST, OrganSMNIST, OrganAMNIST, TissueMNIST)\n",
    "import torchvision.transforms as transforms\n",
    "from ofa.imagenet_classification.networks import ResNets\n",
    "from ofa.imagenet_classification.elastic_nn.modules.dynamic_layers import (\n",
    "    DynamicMBConvLayer, DynamicConvLayer, DynamicLinearLayer\n",
    ")\n",
    "\n",
    "# Dataset mapping configuration\n",
    "DATA_CLASS_MAPPING = {\n",
    "    'PathMNIST': PathMNIST,\n",
    "    'ChestMNIST': ChestMNIST,\n",
    "    'DermaMNIST': DermaMNIST,\n",
    "    'OCTMNIST': OCTMNIST,\n",
    "    'PneumoniaMNIST': PneumoniaMNIST,\n",
    "    'RetinaMNIST': RetinaMNIST,\n",
    "    'BreastMNIST': BreastMNIST,\n",
    "    'BloodMNIST': BloodMNIST,\n",
    "    'TissueMNIST': TissueMNIST,\n",
    "    'OrganAMNIST': OrganAMNIST,\n",
    "    'OrganCMNIST': OrganCMNIST,\n",
    "    'OrganSMNIST': OrganSMNIST\n",
    "}\n",
    "\n",
    "DATA_PATH_MAPPING = {}\n",
    "Main_dir = './work_dir/Supernets'\n",
    "for ds in DATA_CLASS_MAPPING.keys():\n",
    "    dir_path = os.path.join(Main_dir, ds,\"super_net_complete_with_sandwich.pth\")\n",
    "    DATA_PATH_MAPPING[ds] = dir_path\n",
    "\n",
    "print(DATA_PATH_MAPPING)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def sample_active_subnet(supernet, sample_config):\n",
    "    \"\"\"\n",
    "    Sample an active subnet configuration from the supernet.\n",
    "    \n",
    "    Args:\n",
    "        supernet: The supernet model\n",
    "        sample_config (dict): Configuration for sampling\n",
    "        \n",
    "    Returns:\n",
    "        dict: Architecture configuration\n",
    "    \"\"\"\n",
    "    # Sample expand ratio\n",
    "    expand_setting = []\n",
    "    for block in supernet.blocks:\n",
    "        expand_setting.append(random.choice(sample_config['e']))\n",
    "    \n",
    "    # Sample depth\n",
    "    depth_list = sample_config['d'][0]\n",
    "    depth_setting = [random.choice(depth_list)]\n",
    "    for stage_id in range(len(ResNets.BASE_DEPTH_LIST)):\n",
    "        depth_list = sample_config['d'][stage_id + 1]\n",
    "        depth_setting.append(random.choice(depth_list))\n",
    "    \n",
    "    # Sample width multiplier\n",
    "    width_mult_index = [random.choice(sample_config['w'][i]) \n",
    "                       for i in range(len(sample_config['w']))]\n",
    "    width_mult_setting = [\n",
    "        list(range(len(supernet.input_stem[0].out_channel_list)))[width_mult_index[0]],\n",
    "        list(range(len(supernet.input_stem[2].out_channel_list)))[width_mult_index[1]],\n",
    "    ]\n",
    "    for stage_id, block_idx in enumerate(supernet.grouped_block_index):\n",
    "        stage_first_block = supernet.blocks[block_idx[0]]\n",
    "        width_mult_setting.append(\n",
    "            list(range(len(stage_first_block.out_channel_list)))[width_mult_index[stage_id + 2]]\n",
    "        )\n",
    "    \n",
    "    arch_config = {\"d\": depth_setting, \"e\": expand_setting, \"w\": width_mult_setting}\n",
    "    supernet.set_active_subnet(**arch_config)\n",
    "    return arch_config\n",
    "\n",
    "\n",
    "def validate(val_loader, model, criterion, device):\n",
    "    \"\"\"\n",
    "    Validate model on given data loader.\n",
    "    \n",
    "    Args:\n",
    "        val_loader: Data loader for validation\n",
    "        model: Model to validate\n",
    "        criterion: Loss function\n",
    "        device: Device to run on\n",
    "        \n",
    "    Returns:\n",
    "        tuple: (average_loss, accuracy)\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, labels in val_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            \n",
    "            # Handle label format\n",
    "            if labels.size(1) > 1:\n",
    "                labels = torch.argmax(labels, dim=1)\n",
    "            else:\n",
    "                labels = labels.squeeze()\n",
    "            \n",
    "            # Handle single channel images\n",
    "            if images.size(1) == 1:\n",
    "                images = images.repeat(1, 3, 1, 1)\n",
    "            \n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            running_loss += loss.item() * images.size(0)\n",
    "            _, predicted = outputs.max(1)\n",
    "            correct += predicted.eq(labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "    \n",
    "    avg_loss = running_loss / len(val_loader.dataset)\n",
    "    accuracy = 100.0 * correct / total\n",
    "    return avg_loss, accuracy\n",
    "\n",
    "\n",
    "def sample_fixed_subnets(supernet, num_samples=10, seed=42):\n",
    "    \"\"\"\n",
    "    Sample a fixed set of subnets using a deterministic seed.\n",
    "    \n",
    "    Args:\n",
    "        supernet: The supernet model\n",
    "        num_samples (int): Number of subnets to sample\n",
    "        seed (int): Random seed for reproducibility\n",
    "        \n",
    "    Returns:\n",
    "        list: List of sampled configurations\n",
    "    \"\"\"\n",
    "    random.seed(seed)\n",
    "    sampled_configs = []\n",
    "    sample_config = {\n",
    "        'd': [[0, 1, 2], [0, 1, 2], [0, 1, 2], [0, 1, 2], [0, 1, 2]],\n",
    "        'e': [0.2, 0.25, 0.35],\n",
    "        'w': [[0, 1, 2], [0, 1, 2], [0, 1, 2], [0, 1, 2], [0, 1, 2], [0,1,2]]\n",
    "    }\n",
    "    \n",
    "    for _ in range(num_samples):\n",
    "        sampled_configs.append(sample_active_subnet(supernet, sample_config))\n",
    "    \n",
    "    return sampled_configs\n",
    "\n",
    "\n",
    "def evaluate_subnets(supernet, sampled_configs, val_loader, test_loader, device):\n",
    "    \"\"\"\n",
    "    Evaluate sampled subnets and compute performance metrics.\n",
    "    \n",
    "    Args:\n",
    "        supernet: The supernet model\n",
    "        sampled_configs (list): List of subnet configurations\n",
    "        val_loader: Validation data loader\n",
    "        test_loader: Test data loader\n",
    "        device: Device to run on\n",
    "        \n",
    "    Returns:\n",
    "        list: List of evaluation results\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "    supernet.to(device)\n",
    "    supernet.eval()\n",
    "    \n",
    "    for config in tqdm(sampled_configs, desc=\"Evaluating sampled subnets\"):\n",
    "        supernet.set_active_subnet(**config)\n",
    "        subnet = supernet.get_active_subnet()\n",
    "        \n",
    "        # Compute validation and test accuracy\n",
    "        val_loss, val_acc = validate(val_loader, subnet, criterion, device)\n",
    "        test_loss, test_acc = validate(test_loader, subnet, criterion, device)\n",
    "        \n",
    "        results.append({\n",
    "            \"subnet_config\": {'w': config['w'], 'd': config['d'],'e': config['e']},\n",
    "            \"num_parameters\": sum(p.numel() for p in subnet.parameters()),\n",
    "            \"val_accuracy\": val_acc,\n",
    "            \"test_accuracy\": test_acc,\n",
    "        })\n",
    "    \n",
    "    return results\n",
    "\n",
    "\n",
    "def get_functional_encoding(model, num_samples=64, seed=42):\n",
    "    \"\"\"\n",
    "    Compute functional encoding of a model using embeddings of Gaussian noise.\n",
    "    \n",
    "    Args:\n",
    "        model: Model to encode\n",
    "        num_samples (int): Number of noise samples\n",
    "        seed (int): Random seed\n",
    "        \n",
    "    Returns:\n",
    "        torch.Tensor: Functional encoding\n",
    "    \"\"\"\n",
    "    torch.manual_seed(seed)\n",
    "    x = torch.randn(num_samples, 3, 224, 224)\n",
    "    linear = model.classifier.copy()\n",
    "    model.classifier = torch.nn.Identity()\n",
    "    embed = model(x)\n",
    "    model.classifier = linear\n",
    "    return embed\n",
    "\n",
    "\n",
    "def load_and_evaluate_supernet(dataset_name, device='cuda:0', num_samples=1000):\n",
    "    \"\"\"\n",
    "    Load supernet and evaluate subnets for a given dataset.\n",
    "    \n",
    "    Args:\n",
    "        dataset_name (str): Name of the dataset\n",
    "        work_dir (str): Working directory path\n",
    "        device (str): Device to use\n",
    "        num_samples (int): Number of subnets to sample\n",
    "        \n",
    "    Returns:\n",
    "        list: Evaluation results\n",
    "    \"\"\"\n",
    "    \n",
    "    model_path = DATA_PATH_MAPPING.get(dataset_name)\n",
    "    \n",
    "    if not os.path.exists(model_path):\n",
    "        raise FileNotFoundError(f\"Supernet not found at {model_path}\")\n",
    "    \n",
    "    # Load supernet\n",
    "    supernet = torch.hub.load('mit-han-lab/once-for-all', 'ofa_supernet_resnet50', pretrained=True)\n",
    "    n_classes = 7  # Assuming 7 classes for DermaMNIST, adjust as needed\n",
    "    \n",
    "    # Modify classifier for the dataset\n",
    "    supernet.classifier = DynamicLinearLayer([supernet.classifier.linear.linear.in_features], n_classes)\n",
    "    supernet = supernet.to(device)\n",
    "    supernet.load_state_dict(torch.load(model_path, map_location=device)['state_dict'])\n",
    "    \n",
    "    # Load data\n",
    "    val_loader, test_loader = get_dataloaders(dataset_name=dataset_name,batch_size=256)\n",
    "    \n",
    "    # Sample and evaluate subnets\n",
    "    sampled_configs = sample_fixed_subnets(supernet, num_samples=num_samples, seed=42)\n",
    "    results = evaluate_subnets(supernet, sampled_configs, val_loader, test_loader, device)\n",
    "    \n",
    "    return results\n",
    "\n",
    "\n",
    "def aggregate_dataset_results():\n",
    "    \"\"\"\n",
    "    Aggregate results from multiple datasets into a single file.\n",
    "    \"\"\"\n",
    "    # File containing dataset encodings\n",
    "    encoding_file = './outputs/medmnist_resnet50_encodings.pth'\n",
    "    \n",
    "    # Load the dataset encodings\n",
    "    dataset_encodings = torch.load(encoding_file)\n",
    "    aggregated_data = []\n",
    "    \n",
    "    # Iterate over each dataset\n",
    "    for dataset_name, encoding in dataset_encodings.items():\n",
    "        if dataset_name not in DATA_PATH_MAPPING.keys():\n",
    "            print(f\"Warning: Dataset '{dataset_name}' not found in mapping. Skipping.\")\n",
    "            continue\n",
    "            \n",
    "        subnets_file = DATA_PATH_MAPPING.get(dataset_name)\n",
    "        if not os.path.exists(subnets_file):\n",
    "            print(f\"Warning: Subnets file for '{dataset_name}' not found at {subnets_file}. Skipping.\")\n",
    "            continue\n",
    "        \n",
    "        # Load the subnets info\n",
    "        subnets_info = torch.load(subnets_file)\n",
    "        \n",
    "        # Aggregate data for each subnet\n",
    "        data_encoding = torch.mean(encoding, dim=0)\n",
    "        \n",
    "        for subnet_info in subnets_info:\n",
    "            model_encoding = torch.mean(subnet_info.get(\"functional\"), dim=0)\n",
    "            \n",
    "            sample = {\n",
    "                \"dataset_name\": dataset_name,\n",
    "                \"dataset_encoding\": data_encoding,\n",
    "                \"topology\": subnet_info.get(\"topology\"),\n",
    "                \"val_accuracy\": subnet_info.get(\"val_accuracy\"),\n",
    "                \"val_loss\": subnet_info.get(\"val_loss\"),\n",
    "                \"test_loss\": subnet_info.get(\"test_loss\"),\n",
    "                \"test_accuracy\": subnet_info.get(\"test_accuracy\"),\n",
    "                \"functional\": model_encoding,\n",
    "            }\n",
    "            aggregated_data.append(sample)\n",
    "    \n",
    "    # Save aggregated data\n",
    "    output_file = \"aggregated_dataset_source.pth\"\n",
    "    torch.save(aggregated_data, output_file)\n",
    "    print(f\"Aggregated dataset source file saved to: {output_file}\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Example usage\n",
    "    dataset_name = \"DermaMNIST\"\n",
    "    results = load_and_evaluate_supernet(dataset_name, num_samples=10)\n",
    "\n",
    "    print(f\"Evaluation completed for {dataset_name}\")\n",
    "    print(f\"Number of results: {len(results)}\")\n",
    "    print(results)\n",
    "    \n",
    "    # Aggregate results\n",
    "    #aggregate_dataset_results()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "67f8abdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'PathMNIST': './work_dir/Supernets/PathMNIST/super_net_complete_with_sandwich.pth', 'ChestMNIST': './work_dir/Supernets/ChestMNIST/super_net_complete_with_sandwich.pth', 'DermaMNIST': './work_dir/Supernets/DermaMNIST/super_net_complete_with_sandwich.pth', 'OCTMNIST': './work_dir/Supernets/OCTMNIST/super_net_complete_with_sandwich.pth', 'PneumoniaMNIST': './work_dir/Supernets/PneumoniaMNIST/super_net_complete_with_sandwich.pth', 'RetinaMNIST': './work_dir/Supernets/RetinaMNIST/super_net_complete_with_sandwich.pth', 'BreastMNIST': './work_dir/Supernets/BreastMNIST/super_net_complete_with_sandwich.pth', 'BloodMNIST': './work_dir/Supernets/BloodMNIST/super_net_complete_with_sandwich.pth', 'TissueMNIST': './work_dir/Supernets/TissueMNIST/super_net_complete_with_sandwich.pth', 'OrganAMNIST': './work_dir/Supernets/OrganAMNIST/super_net_complete_with_sandwich.pth', 'OrganCMNIST': './work_dir/Supernets/OrganCMNIST/super_net_complete_with_sandwich.pth', 'OrganSMNIST': './work_dir/Supernets/OrganSMNIST/super_net_complete_with_sandwich.pth'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/lotfimecharbat/.cache/torch/hub/mit-han-lab_once-for-all_master\n",
      "/home/lotfimecharbat/Projects/MedNNS/ofa/model_zoo.py:106: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  init = torch.load(pt_path, map_location=\"cpu\")[\"state_dict\"]\n",
      "/home/lotfimecharbat/Projects/MedNNS/meta_space_builder/model_encoder.py:246: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  supernet.load_state_dict(torch.load(model_path, map_location=device)['state_dict'])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using downloaded and verified file: /home/lotfimecharbat/.medmnist/dermamnist.npz\n",
      "Using downloaded and verified file: /home/lotfimecharbat/.medmnist/dermamnist.npz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating sampled subnets: 100%|██████████| 100/100 [10:02<00:00,  6.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved to ./work_dir/Supernets/DermaMNIST/DermaMNIST_subnet_evaluation_results.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from meta_space_builder import model_encoder_main\n",
    "results = model_encoder_main('DermaMNIST', device='cuda:0', num_samples=100)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nns",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
